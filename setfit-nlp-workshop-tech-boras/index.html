<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>Train Text Classifiers with 8 Examples: SetFit Few-Shot Learning Tutorial - Pine Grove Interactive</title><meta name=Description content="Learn how to build text classifiers with just a handful of training examples using SetFit and Transformer models. A perfect first AI project for businesses. Practical tutorial from Tech Borås AI Lab Workshop 2."><meta property="og:url" content="https://pgi.dev/setfit-nlp-workshop-tech-boras/">
<meta property="og:site_name" content="Pine Grove Interactive"><meta property="og:title" content="Powerful NLP with SetFit and Few-Shot Learning"><meta property="og:description" content="Learn how to build text classifiers with just a handful of training examples using SetFit and Transformer models. A perfect first AI project for businesses. Practical tutorial from Tech Borås AI Lab Workshop 2."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-09-10T15:00:00+01:00"><meta property="article:modified_time" content="2025-11-29T11:49:04+01:00"><meta property="og:image" content="https://pgi.dev/images/tree.svg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://pgi.dev/images/tree.svg"><meta name=twitter:title content="Powerful NLP with SetFit and Few-Shot Learning"><meta name=twitter:description content="Learn how to build text classifiers with just a handful of training examples using SetFit and Transformer models. A perfect first AI project for businesses. Practical tutorial from Tech Borås AI Lab Workshop 2."><meta name=application-name content="Pine Grove Interactive"><meta name=apple-mobile-web-app-title content="Pine Grove Interactive"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel=icon href=/images/favicon.svg><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://pgi.dev/setfit-nlp-workshop-tech-boras/><link rel=prev href=https://pgi.dev/intro-to-ml-workshop-tech-boras/><link rel=next href=https://pgi.dev/mlops-workshop-tech-boras/><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/normalize.css@8.0.1/normalize.min.css><link rel=stylesheet href=/css/style.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Powerful NLP with SetFit and Few-Shot Learning","inLanguage":"en","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/pgi.dev\/setfit-nlp-workshop-tech-boras\/"},"image":["https:\/\/pgi.dev\/images\/apple-touch-icon.png"],"genre":"posts","wordcount":1521,"url":"https:\/\/pgi.dev\/setfit-nlp-workshop-tech-boras\/","datePublished":"2025-09-10T15:00:00+01:00","dateModified":"2025-11-29T11:49:04+01:00","publisher":{"@type":"Organization","name":"xxxx","logo":"https:\/\/pgi.dev\/images\/tree.svg"},"author":{"@type":"Person","name":"Kristoffer Johansson"},"description":"Learn how to build text classifiers with just a handful of training examples using SetFit and Transformer models. A perfect first AI project for businesses. Practical tutorial from Tech Borås AI Lab Workshop 2."}</script></head><body data-header-desktop=fixed data-header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem("theme")?localStorage.getItem("theme")==="dark":"auto"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"auto"==="dark")&&document.body.setAttribute("theme","dark")</script><script defer src=https://cloud.umami.is/script.js data-website-id=6621ff6c-2172-46d3-96e6-c04c97e6890f></script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="Pine Grove Interactive"><img class="lazyload logo" src=/svg/loading.min.svg data-src=/images/logo-pgi-dev.svg data-srcset="/images/logo-pgi-dev.svg, /images/logo-pgi-dev.svg 1.5x, /images/logo-pgi-dev.svg 2x" data-sizes=auto alt=Home title=Home></a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>Blog </a><a class=menu-item href=/offer/>Our offer </a><a class=menu-item href=/about/>About </a><span class="menu-item delimiter"></span><a href=javascript:void(0); class="menu-item language" title="Select Language">English<i class="fas fa-chevron-right fa-fw" aria-hidden=true></i>
<select class=language-select id=language-select-desktop onchange="location=this.value"><option value=/sv/setfit-nlp-workshop-tech-boras/>Svenska</option><option value=/setfit-nlp-workshop-tech-boras/ selected>English</option></select>
</a><span class="menu-item search" id=search-desktop><input type=text placeholder="Search titles or contents..." id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=Search><i class="fas fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=Clear><i class="fas fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i>
</span></span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme"><i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="Pine Grove Interactive"><img class="lazyload logo" src=/svg/loading.min.svg data-src=/images/logo-pgi-dev.svg data-srcset="/images/logo-pgi-dev.svg, /images/logo-pgi-dev.svg 1.5x, /images/logo-pgi-dev.svg 2x" data-sizes=auto alt=/images/logo-pgi-dev.svg title=/images/logo-pgi-dev.svg></a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder="Search titles or contents..." id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=Search><i class="fas fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=Clear><i class="fas fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>Cancel</a></div><a class=menu-item href=/posts/ title>Blog</a><a class=menu-item href=/offer/ title>Our offer</a><a class=menu-item href=/about/ title>About</a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class=menu-item title="Select Language">English<i class="fas fa-chevron-right fa-fw" aria-hidden=true></i>
<select class=language-select onchange="location=this.value"><option value=/sv/setfit-nlp-workshop-tech-boras/>Svenska</option><option value=/setfit-nlp-workshop-tech-boras/ selected>English</option></select></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>Contents</h2><div class=toc-content id=toc-content-auto></div></div><article class="page single"><h1 class=single-title>Powerful NLP with SetFit and Few-Shot Learning</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=https://www.linkedin.com/in/kristoffer-johansson/ title=Author target=_blank rel="noopener noreffer author" class=author><i class="fas fa-user-circle fa-fw" aria-hidden=true></i>Kristoffer Johansson</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw" aria-hidden=true></i>&nbsp;<time datetime=2025-09-10>2025-09-10</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden=true></i>&nbsp;1521 words&nbsp;
<i class="far fa-clock fa-fw" aria-hidden=true></i>&nbsp;8 minutes&nbsp;</div></div><div class="details toc" id=toc-static data-kept><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#the-challenge-of-limited-training-data>The challenge of limited training data</a></li><li><a href=#how-transformers-changed-nlp>How Transformers changed NLP</a></li><li><a href=#understanding-semantic-similarity-in-text>Understanding semantic similarity in text</a></li><li><a href=#setfit-few-shot-learning-for-text-classification>SetFit: Few-Shot Learning for Text Classification</a></li><li><a href=#building-a-text-classifier-with-setfit>Building a text classifier with SetFit</a><ul><li><a href=#installation>Installation</a></li><li><a href=#complete-training-pipeline>Complete Training Pipeline</a></li><li><a href=#what-this-code-does>What this code does</a></li></ul></li><li><a href=#running-locally-with-gpu>Running locally with GPU</a><ul><li><a href=#local-vs-cloud-development>Local vs Cloud Development</a></li><li><a href=#alternative-kaggle-notebooks>Alternative: Kaggle Notebooks</a></li></ul></li><li><a href=#get-started-with-few-shot-nlp>Get started with few-shot NLP</a></li><li><a href=#nlp--ai-consulting-in-borås>NLP & AI Consulting in Borås</a></li></ul></nav></div></div><div class=content id=content><p>On September 9, I ran the second workshop in the AI Lab series at University of Borås. This time we tackled a common business problem that you run into all the time when starting an AI project: You have the data, but it is unlabeled. This post shows how to handle that challenge with few-shot learning.</p><figure><a class=lightgallery href=/setfit-nlp-workshop-tech-boras/tech-boras-workshop-2.webp title=/setfit-nlp-workshop-tech-boras/tech-boras-workshop-2.webp data-thumbnail=/setfit-nlp-workshop-tech-boras/tech-boras-workshop-2.webp data-sub-html="<h2>Workshop om Transformers och SetFit på Högskolan i Borås, 9 september</h2>"><img class=lazyload src=/svg/loading.min.svg data-src=/setfit-nlp-workshop-tech-boras/tech-boras-workshop-2.webp data-srcset="/setfit-nlp-workshop-tech-boras/tech-boras-workshop-2.webp, /setfit-nlp-workshop-tech-boras/tech-boras-workshop-2.webp 1.5x, /setfit-nlp-workshop-tech-boras/tech-boras-workshop-2.webp 2x" data-sizes=auto alt=/setfit-nlp-workshop-tech-boras/tech-boras-workshop-2.webp width=1280 height=720></a><figcaption class=image-caption>Workshop om Transformers och SetFit på Högskolan i Borås, 9 september</figcaption></figure><p>Modern NLP (Natural Language Processing) tools like SetFit make few-shot learning practical with code you can run locally on your own hardware. Small language models like BERT variants are lightweight enough to run on consumer GPUs, making advanced NLP accessible without cloud infrastructure dependency or recurring costs. This is an excellent first AI/ML project for companies wanting to get started with data-driven work!</p><h2 id=the-challenge-of-limited-training-data>The challenge of limited training data</h2><p>Text classification solves real business problems. To mention a few, you can: sort support tickets by priority, filter out spam, route customer inquiries to the right department, analyze sentiment (what people think) in product reviews.</p><p>A traditional machine learning approach requires thousands of labeled examples in a so-called dataset. That means you need someone to manually label 5,000+ emails as &ldquo;spam&rdquo; or &ldquo;not spam&rdquo; before training a model can begin. That can be expensive and slow (and boring), which means most organizations don&rsquo;t have thousands of pre-labeled examples sitting around.</p><p>This is where the SetFit method comes in: it uses powerful pre-trained transformer models that we fine-tune on as few as two examples per class. Much easier to manage than 5,000 examples!</p><h2 id=how-transformers-changed-nlp>How Transformers changed NLP</h2><p>Transformer models like BERT revolutionized natural language processing by understanding word context. Unlike older methods that treat words as isolated tokens, BERT captures meaning based on surrounding words.</p><p>Consider these sentences:</p><ul><li>&ldquo;He biked to work.&rdquo;</li><li>&ldquo;He drove his car to work.&rdquo;</li><li>&ldquo;Peter decided to take his bike to the beach.&rdquo;</li></ul><p>BERT understands that &ldquo;biked&rdquo; and &ldquo;bike&rdquo; relate to the same concept, while &ldquo;drove his car&rdquo; represents a different mode of transport. This contextual understanding is what makes modern NLP powerful. And what&rsquo;s extra good is that there are open-source platforms like <a href=https://huggingface.co/ target=_blank rel="noopener noreffer">HuggingFace</a>
filled with these small, pre-trained BERT models that already know a lot about our world. We just need to provide a few examples of our task to retrain the models to become good at what we want.</p><h2 id=understanding-semantic-similarity-in-text>Understanding semantic similarity in text</h2><p>The context in which you read a text matters for the concept of &ldquo;similarity&rdquo;. Whether two sentences are &ldquo;similar&rdquo; depends entirely on what you&rsquo;re measuring. If we look from the perspective of public transportation, we might be interested in knowing which mode of transport is mentioned in the text. Then we can imagine that examples might be paired like this:</p><p><strong>Negative pair</strong> (different modes of transport):</p><ul><li>&ldquo;He biked to work.&rdquo;</li><li>&ldquo;He drove his car to work.&rdquo;</li></ul><p><strong>Positive pair</strong> (same mode of transport):</p><ul><li>&ldquo;He biked to work.&rdquo;</li><li>&ldquo;Peter decided to take his bike to the beach.&rdquo;</li></ul><p><strong>Negative pair</strong> (different modes of transport):</p><ul><li>&ldquo;Peter decided to take his bike to the beach.&rdquo;</li><li>&ldquo;He drove his car to work.&rdquo;</li></ul><p>But if we&rsquo;re interested in knowing where someone is going, we would need to pair the examples in a completely different way. This is important because transformer models learn these contextual relationships from massive datasets when they were initially trained. That means the models have seen data that might not match exactly what you want to measure! And this is where SetFit comes in.</p><h2 id=setfit-few-shot-learning-for-text-classification>SetFit: Few-Shot Learning for Text Classification</h2><p>SetFit combines pre-trained Transformer models with efficient fine-tuning on your problem from the perspective you want to adopt. That is, is it interesting to know the mode of transport or the destination? And thanks to SetFit, we can achieve very high accuracy with just 2-16 labeled examples.</p><p>SetFit works in two stages:</p><ol><li><strong>Contrastive learning</strong>: Train on sentence pairs to learn which examples are similar and which are different</li><li><strong>Classification head</strong>: Train a simple classifier on top of the learned embeddings</li></ol><p>Doing it this way leverages the vast knowledge already baked into transformer models. You&rsquo;re not teaching the model language and concepts from scratch. Instead, you&rsquo;re teaching it your specific classification task using the language understanding the model already has.</p><p>This gives us fast, lightweight, production-ready text classifiers trained on a fraction of the data that traditional methods require.</p><h2 id=building-a-text-classifier-with-setfit>Building a text classifier with SetFit</h2><p>This example is based on the workshop repository: <a href=https://github.com/krjoha/ai-lab-setfit target=_blank rel="noopener noreffer">github.com/krjoha/ai-lab-setfit</a></p><p>If you want to see the full example, you can look at one of the notebooks in the repository. Here&rsquo;s a code example from there:</p><h3 id=installation>Installation</h3><p>Use <code>uv</code> to create a virtual python environment.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Create a virtual environment in a .venv folder and install all project dependencies</span>
</span></span><span class=line><span class=cl>uv sync
</span></span></code></pre></td></tr></table></div></div><h3 id=complete-training-pipeline>Complete Training Pipeline</h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>datasets</span> <span class=kn>import</span> <span class=n>load_dataset</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>setfit</span> <span class=kn>import</span> <span class=n>SetFitModel</span><span class=p>,</span> <span class=n>Trainer</span><span class=p>,</span> <span class=n>TrainingArguments</span><span class=p>,</span> <span class=n>sample_dataset</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Load the Amazon Massive Intent dataset (Swedish)</span>
</span></span><span class=line><span class=cl><span class=n>train_dataset</span> <span class=o>=</span> <span class=n>load_dataset</span><span class=p>(</span><span class=s2>&#34;SetFit/amazon_massive_intent_sv-SE&#34;</span><span class=p>,</span> <span class=n>split</span><span class=o>=</span><span class=s2>&#34;train&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>test_dataset</span> <span class=o>=</span> <span class=n>load_dataset</span><span class=p>(</span><span class=s2>&#34;SetFit/amazon_massive_intent_sv-SE&#34;</span><span class=p>,</span> <span class=n>split</span><span class=o>=</span><span class=s2>&#34;test&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Sample just 1 example per class (60 examples from 60 intent classes)</span>
</span></span><span class=line><span class=cl><span class=n>train_sample</span> <span class=o>=</span> <span class=n>sample_dataset</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>train_dataset</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>label_column</span><span class=o>=</span><span class=s2>&#34;label&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>num_samples</span><span class=o>=</span><span class=mi>1</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Load a pre-trained embedding model</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>SetFitModel</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&#34;nomic-ai/modernbert-embed-base&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Configure training</span>
</span></span><span class=line><span class=cl><span class=n>args</span> <span class=o>=</span> <span class=n>TrainingArguments</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>batch_size</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>num_epochs</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Initialize trainer</span>
</span></span><span class=line><span class=cl><span class=n>trainer</span> <span class=o>=</span> <span class=n>Trainer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>=</span><span class=n>model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>args</span><span class=o>=</span><span class=n>args</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>train_dataset</span><span class=o>=</span><span class=n>train_sample</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>eval_dataset</span><span class=o>=</span><span class=n>test_dataset</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>metric</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Train the model</span>
</span></span><span class=line><span class=cl><span class=n>trainer</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Evaluate on test set</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>trainer</span><span class=o>.</span><span class=n>evaluate</span><span class=p>(</span><span class=n>test_dataset</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Accuracy: </span><span class=si>{</span><span class=n>results</span><span class=p>[</span><span class=s1>&#39;accuracy&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2%</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Make predictions on new Swedish text</span>
</span></span><span class=line><span class=cl><span class=n>predictions</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>([</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Släck lampan&#34;</span><span class=p>,</span>           <span class=c1># Turn off the light</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;spela vikingarna&#34;</span><span class=p>,</span>       <span class=c1># Play Vikingarna (music)</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;starta dammsugaren&#34;</span><span class=p>,</span>     <span class=c1># Start the vacuum cleaner</span>
</span></span><span class=line><span class=cl><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>predictions</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=what-this-code-does>What this code does</h3><ol><li><strong>Dataset loading</strong>: Load Amazon Massive Intent dataset with 60 different intent classes in Swedish</li><li><strong>Few-shot sampling</strong>: Sample just 1 example per class (60 total examples from 11,514 available)</li><li><strong>Model initialization</strong>: Load a pre-trained multilingual embedding model</li><li><strong>Training</strong>: The trainer generates sentence pairs and fine-tunes the model</li><li><strong>Evaluation</strong>: Test accuracy on 2,974 unseen examples</li><li><strong>Prediction</strong>: Classify new Swedish voice assistant commands</li></ol><p>With just 60 examples total (1 per class), this model achieves sufficiently high accuracy to become useful for so-called &ldquo;intent classification&rdquo;. As mentioned, traditional approaches would need thousands of examples per class to achieve similar results.</p><h2 id=running-locally-with-gpu>Running locally with GPU</h2><p>Small language models like BERT are lightweight enough to run on consumer GPUs. Unlike large language models, models like <code>modernbert-embed-base</code> require only a few gigabytes of GPU memory.</p><p>Training Transformer models needs GPU acceleration. Even with SetFit&rsquo;s efficiency, CPU training can sometimes be slow and impractical. So it&rsquo;s good to use your computer&rsquo;s GPU if there is one. You can check that by running:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Verify NVIDIA GPU is detected</span>
</span></span><span class=line><span class=cl>nvidia-smi
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># For Macbook with Apple Silicon (M1/M2/M3/M4/M5)</span>
</span></span><span class=line><span class=cl><span class=c1># PyTorch will automatically detect and use MPS (Metal Performance Shaders)</span>
</span></span></code></pre></td></tr></table></div></div><p>If you have an NVIDIA GPU with CUDA support or a Macbook with Apple Silicon, PyTorch will use hardware acceleration automatically. The training code above with 60 examples takes a few seconds instead of several hours with only CPU.</p><h3 id=local-vs-cloud-development>Local vs Cloud Development</h3><p>Running locally gives you control. No session timeouts. No random disconnects. Work directly with local datasets. Your environment persists between sessions.</p><p>But if you don&rsquo;t have local GPU access, Kaggle provides free GPU notebooks.</p><h3 id=alternative-kaggle-notebooks>Alternative: Kaggle Notebooks</h3><p>Kaggle offers free GPU in their notebook environment. But it requires a registered account + phone verification to prevent abuse. In exchange, you get access to an Nvidia T4 GPU.</p><p><strong>Phone verification:</strong></p><ol><li>Log into your account at <a href=https://www.kaggle.com/settings target=_blank rel="noopener noreffer">kaggle.com/settings</a></li><li>Follow the instructions to add your phone number</li><li>After verification, your notebooks get internet access and GPU support</li></ol><p><strong>Enable GPU:</strong></p><ol><li>Open the Kaggle Notebook</li><li>Click <strong>Settings</strong> → <strong>Accelerator</strong> → <strong>GPU T4 x2</strong> (avoid P100, it&rsquo;s older)</li><li>Your session now has GPU acceleration</li></ol><p><strong>Install SetFit:</strong></p><ol><li>Run the first cell to start your session</li><li>Click <strong>Add-ons</strong> → <strong>Install Dependencies</strong></li><li>Paste: <code>pip install setfit</code></li><li>Click <strong>Run</strong>, then <strong>Save</strong></li></ol><p>There&rsquo;s a version of the workshop notebook on Kaggle with these packages pre-configured.</p><h2 id=get-started-with-few-shot-nlp>Get started with few-shot NLP</h2><p>SetFit makes it possible to solve real business problems with NLP without needing thousands of labeled examples. Because pre-trained transformer models already understand language, you just need to teach them your specific task. This requires far less data than training from scratch. An excellent first project!</p><p>Want to try it yourself? Clone the workshop repository and train your first few-shot classifier:</p><p><strong>Repository</strong>: <a href=https://github.com/krjoha/ai-lab-setfit target=_blank rel="noopener noreffer">github.com/krjoha/ai-lab-setfit</a></p><p>You can have a working text classifier running in under 10 minutes. And it&rsquo;s free to run locally if you have a GPU in your computer!</p><figure><a class=lightgallery href=/setfit-nlp-workshop-tech-boras/ceo.webp title=/setfit-nlp-workshop-tech-boras/ceo.webp data-thumbnail=/setfit-nlp-workshop-tech-boras/ceo.webp data-sub-html="<h2>Kristoffer Johansson, lecturer and create of the AI Lab concept at Tech Borås</h2>"><img class=lazyload src=/svg/loading.min.svg data-src=/setfit-nlp-workshop-tech-boras/ceo.webp data-srcset="/setfit-nlp-workshop-tech-boras/ceo.webp, /setfit-nlp-workshop-tech-boras/ceo.webp 1.5x, /setfit-nlp-workshop-tech-boras/ceo.webp 2x" data-sizes=auto alt=/setfit-nlp-workshop-tech-boras/ceo.webp width=1200 height=802></a><figcaption class=image-caption>Kristoffer Johansson, lecturer and create of the AI Lab concept at Tech Borås</figcaption></figure><h2 id=nlp--ai-consulting-in-borås>NLP & AI Consulting in Borås</h2><p>This workshop was part of the AI Lab series at University of Borås, focused on practical AI and NLP for developers. I provide AI and data engineering consulting for businesses in Borås and throughout Sweden. If you need help implementing NLP solutions or want to explore few-shot learning for your use case, reach out.</p></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Updated on 2025-11-29&nbsp;<a class=git-hash href=https://github.com/krjoha/pine-grove/commit/fd45129f1e1d174d51f61df278c0cd0e8519d7c4 target=_blank title="commit by Kristoffer Johansson(10258920+krjoha@users.noreply.github.com) fd45129f1e1d174d51f61df278c0cd0e8519d7c4: Blog post about SetFit (#5)">
<i class="fas fa-hashtag fa-fw" aria-hidden=true></i>fd45129f</a></span></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span></span></div></div></div><div class=post-info-more><section class=post-tags></section><section><span><a href=javascript:void(0); onclick=window.history.back()>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span></section></div><div class=post-nav><a href=/intro-to-ml-workshop-tech-boras/ class=prev rel=prev title="Machine Learning Workshop in Borås"><i class="fas fa-angle-left fa-fw" aria-hidden=true></i>Machine Learning Workshop in Borås</a>
<a href=/mlops-workshop-tech-boras/ class=next rel=next title="From Jupyter Notebooks to Production: MLOps Workshop at Tech Borås">From Jupyter Notebooks to Production: MLOps Workshop at Tech Borås<i class="fas fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line itemscope itemtype=http://schema.org/CreativeWork><i class="far fa-copyright fa-fw" aria-hidden=true></i><span itemprop=copyrightYear>2025</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=https://www.linkedin.com/in/kristoffer-johansson/ target=_blank>Kristoffer Johansson</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=/about target=_blank>PGI AB</a></span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw" aria-hidden=true></i>
</a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw" aria-hidden=true></i></a></div><script type=text/javascript src=https://cdn.jsdelivr.net/npm/autocomplete.js@0.38.1/dist/autocomplete.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lunr@2.3.9/lunr.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lazysizes@5.3.1/lazysizes.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js></script><script type=text/javascript>window.config={code:{copyTitle:"Copy to clipboard",maxShownLines:50},comment:{},search:{highlightTag:"em",lunrIndexURL:"/index.json",maxResultLength:10,noResultsFound:"No results found",snippetLength:30,type:"lunr"}}</script><script type=text/javascript src=/js/theme.min.js></script></body></html>