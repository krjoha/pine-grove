[{"categories":null,"content":"From 'throwing models over the fence' to automated ML pipelines. A practical guide to MLOps using MLflow and Airflow, based on the third workshop in Tech Bor√•s AI Lab series.","date":"2025-09-23","objectID":"/mlops-workshop-tech-boras/","tags":null,"title":"From Jupyter Notebooks to Production: MLOps Workshop at Tech Bor√•s","uri":"/mlops-workshop-tech-boras/"},{"categories":null,"content":"On September 23, I ran the third workshop in the AI Lab series at University of Bor√•s. This time we tackled the gap between experimentation and production: the ‚Äúthrow it over the fence‚Äù problem that kills ML projects. This post shows how to bridge that gap with MLOps practices and tools. MLOps workshop at University of Bor√•s, September 23 ","date":"2025-09-23","objectID":"/mlops-workshop-tech-boras/:0:0","tags":null,"title":"From Jupyter Notebooks to Production: MLOps Workshop at Tech Bor√•s","uri":"/mlops-workshop-tech-boras/"},{"categories":null,"content":"The Development Environment Problem Most ML projects start in Jupyter notebooks. You load data, explore it, train a model, validate it, and call it done. This works for experimentation, but it creates a problem: the entire workflow lives on your laptop in a linear, manual process. The typical data science workflow: Data Analysis - Explore and understand your dataset Preprocessing - Clean and transform data Model Training - Fit your model to the data Model Validation - Check if it actually works Model Handover - Hope someone can deploy it Each step runs manually. No automation. No versioning. No way to reproduce results reliably. When your model performs well in validation, you face a question: how do you get this into production? The handover problem scales differently, but exists everywhere At a small company, one person handles everything from data analysis to deployment. The handover happens between different hats the same person wears. At medium and large companies, data scientists build models but struggle to hand them over to engineering teams. The model that worked perfectly in a notebook fails in production, or worse, sits unused because deployment is too difficult. MLOps practices built on CI/CD principles solve this by eliminating the handover entirely. Instead of passing artifacts between teams or roles, you build automated pipelines that move code from experimentation to production. The same pipeline that trains your model also deploys it. ","date":"2025-09-23","objectID":"/mlops-workshop-tech-boras/:1:0","tags":null,"title":"From Jupyter Notebooks to Production: MLOps Workshop at Tech Bor√•s","uri":"/mlops-workshop-tech-boras/"},{"categories":null,"content":"The ‚ÄúThrow Over the Fence‚Äù Anti-Pattern When organizations try to scale their ML work, they hit a wall. Literally. The ‚Äôthrow it over the fence‚Äô workflow: data scientists and engineers work in isolation. Image credits swirlai.com Look at the diagram above. On the left, the data scientist works in Jupyter, connected to the data warehouse. They analyze data, preprocess it, train a model, validate it. At the end of this pipeline sits Model Handover (step 1). Then comes the wall. The brick wall in the middle represents organizational separation. The model artifact gets dumped into a bucket (step 2) and passed to the other side. No training context. No preprocessing code. No validation metrics. Just a pickled model file and hope. On the right side, the software engineer receives this artifact (step 3). They attempt deployment (step 4), wrap it in a container, and expose it to product applications (step 5). Then reality hits. Why this pattern fails The model that achieved 95% accuracy in the notebook gets 60% in production. Why? Different data distributions: Training used last month‚Äôs data, production sees today‚Äôs data Missing preprocessing: The notebook had 10 cells of data cleaning that never got documented Dependency mismatches: Model trained with scikit-learn 1.4, production runs 1.0 No monitoring: When accuracy drops, nobody notices for weeks This workflow breaks because it treats model development and deployment as separate problems. The data scientist optimizes for accuracy in experiments. The engineer optimizes for reliability in production. These goals conflict when there‚Äôs a wall between them. Documentation doesn‚Äôt fix this. READMEs get outdated. Comments get ignored. What you need is shared infrastructure that both roles interact with during their work. ","date":"2025-09-23","objectID":"/mlops-workshop-tech-boras/:2:0","tags":null,"title":"From Jupyter Notebooks to Production: MLOps Workshop at Tech Bor√•s","uri":"/mlops-workshop-tech-boras/"},{"categories":null,"content":"The MLOps Solution: Production Architecture The solution replaces the wall with shared infrastructure. Instead of two isolated environments, you build automated pipelines that connect data, training, and deployment. Production MLOps architecture with automated pipelines and centralized metadata tracking. Image credits swirlai.com The diagram shows a production ML environment. Three automated pipelines replace manual handoffs: Data Engineering (warehouse to curated data), ML Training (preprocessing through validation), and Deployment (registry to production). At the center sits a metadata hub with three components: Experiment Tracker: Logs metrics and parameters from every training run ML Metadata Store: Tracks data lineage and artifact relationships Model Registry: Stores versioned models ready for deployment An orchestrator like Airflow runs these pipelines on schedules or triggers, creating a Continuous Training loop where models retrain automatically as data changes. The wall is gone. Both data scientists and engineers interact with the same registry and metadata store. The model that gets deployed is the exact model that was validated, with full lineage tracking. ","date":"2025-09-23","objectID":"/mlops-workshop-tech-boras/:3:0","tags":null,"title":"From Jupyter Notebooks to Production: MLOps Workshop at Tech Bor√•s","uri":"/mlops-workshop-tech-boras/"},{"categories":null,"content":"Building the Pipeline: MLflow + Airflow The workshop put theory into practice. Attendees built a complete MLOps pipeline using MLflow for tracking and Airflow for orchestration, running locally on their laptops. The workshop DAG: automated data generation, prediction, monitoring, and cleanup The tech stack: MLflow: Experiment tracking, metadata store, and model registry Airflow: Pipeline orchestration with a Directed Acyclic Graph (DAG) uv: Fast Python package manager for dependency management ","date":"2025-09-23","objectID":"/mlops-workshop-tech-boras/:4:0","tags":null,"title":"From Jupyter Notebooks to Production: MLOps Workshop at Tech Bor√•s","uri":"/mlops-workshop-tech-boras/"},{"categories":null,"content":"The DAG Structure The diagram shows five tasks that run in sequence and parallel: generate_data (PythonOperator): Simulates new data from a warehouse batch_predict (PythonOperator): Loads the registered model and makes predictions monitor_model (PythonOperator): Checks prediction quality and logs metrics to MLflow After monitoring, two tasks run in parallel: cleanup_old_artifacts (BashOperator): Removes old files generate_summary (PythonOperator): Creates performance reports The DAG interacts with MLflow‚Äôs model registry to fetch the latest production model and logs monitoring metrics to the experiment tracker. ","date":"2025-09-23","objectID":"/mlops-workshop-tech-boras/:4:1","tags":null,"title":"From Jupyter Notebooks to Production: MLOps Workshop at Tech Bor√•s","uri":"/mlops-workshop-tech-boras/"},{"categories":null,"content":"Setup and Installation The full code is available at github.com/krjoha/ai-lab-mlops . The workshop used uv, a fast Python package manager written in Rust that handles dependency resolution and virtual environments. It‚Äôs significantly faster than pip and creates reproducible environments. Both MLflow and Airflow run as local services: MLflow provides the web UI for experiment tracking and model registry at http://localhost:5000, while Airflow runs the scheduler and web interface for DAG management at http://localhost:8080. # Clone the repository git clone https://github.com/krjoha/ai-lab-mlops cd ai-lab-mlops # Install dependencies uv sync source .venv/bin/activate # Start MLflow server (in separate terminal) bash start_mlflow.sh # Start Airflow server (in another terminal) bash start_airflow.sh After starting Airflow, find the username and password in the terminal output or in airflow/simple_auth_manager_passwords.json.generated. ","date":"2025-09-23","objectID":"/mlops-workshop-tech-boras/:4:2","tags":null,"title":"From Jupyter Notebooks to Production: MLOps Workshop at Tech Bor√•s","uri":"/mlops-workshop-tech-boras/"},{"categories":null,"content":"Training and Registering a Model Run the training script to create the initial model: python tasks/train_model.py You can see the stored and versioned model in the MLflow UI at http://localhost:5000/#/experiments. After creating a model and storing it in the MLflow registry, you can go to the Airflow UI at http://localhost:8080 and run the prediction DAG/pipeline from there. The workshop builds a sentiment classification model using scikit-learn‚Äôs Pipeline to chain a TF-IDF vectorizer with logistic regression. Here‚Äôs the core training logic (see tasks/train_model.py for full implementation): # Create pipeline pipeline = Pipeline([ ('tfidf', TfidfVectorizer(max_features=1500, ngram_range=(1, 2))), ('classifier', LogisticRegression(random_state=42, max_iter=1000)) ]) # Train and log with MLflow with mlflow.start_run(experiment_id=experiment_id) as run: # Log parameters and train mlflow.log_param(\"vectorizer_max_features\", 1500) pipeline.fit(df['text'], df['sentiment']) # Log metrics cv_scores = cross_val_score(pipeline, df['text'], df['sentiment'], cv=3) mlflow.log_metric(\"cv_mean_accuracy\", cv_scores.mean()) # Register model in MLflow registry model_info = mlflow.sklearn.log_model(sk_model=pipeline, artifact_path=\"model\") mlflow.register_model(model_uri=model_info.model_uri, name=\"sentiment_classifier\") The key insight: mlflow.register_model() puts the trained model into a central registry where downstream pipelines can load it by name, not by file path. This separation between training and deployment means data scientists can register multiple model versions, and engineers can load the latest version without touching training code. ","date":"2025-09-23","objectID":"/mlops-workshop-tech-boras/:4:3","tags":null,"title":"From Jupyter Notebooks to Production: MLOps Workshop at Tech Bor√•s","uri":"/mlops-workshop-tech-boras/"},{"categories":null,"content":"Model Monitoring The monitoring task analyzes prediction trends over time by querying MLflow‚Äôs experiment tracking. Instead of checking a single accuracy number, it looks at patterns across multiple DAG runs to detect degradation early (see tasks/monitor_model.py for full implementation): def monitor_model(): # Get recent runs from MLflow (last 30 days) runs = mlflow.search_runs( experiment_ids=[experiment.experiment_id], order_by=[\"start_time DESC\"], max_results=50 ) # Analyze trends avg_confidences = runs['metrics.average_confidence'].dropna() low_confidence_rates = runs['metrics.low_confidence_percentage'].dropna() # Generate alerts alerts = [] if avg_confidences.iloc[0] \u003c avg_confidences.iloc[1]: alerts.append(\"Model confidence is declining\") if low_confidence_rates.mean() \u003e 25: alerts.append(f\"High low-confidence rate: {low_confidence_rates.mean():.1f}%\") # Log monitoring results back to MLflow with mlflow.start_run(experiment_id=experiment.experiment_id): mlflow.log_metric(\"overall_avg_confidence\", avg_confidences.mean()) mlflow.log_metric(\"alert_count\", len(alerts)) This creates a feedback loop: predictions generate metrics, monitoring analyzes those metrics across time, and alerts trigger when patterns indicate problems. All tracked in MLflow. The workshop put MLOps theory into practice. Attendees built complete pipelines with MLflow tracking, Airflow orchestration, and automated monitoring running on their own laptops. The same architecture that handled sentiment classification in the workshop scales to fraud detection, recommendation systems, or demand forecasting in production. What makes this approach work is eliminating the handoff. When data scientists and engineers both interact with a shared model registry, the ‚Äúthrow it over the fence‚Äù problem disappears. Automated pipelines catch issues during development, not in production. Monitoring tracks trends across runs instead of waiting for users to report problems. ","date":"2025-09-23","objectID":"/mlops-workshop-tech-boras/:4:4","tags":null,"title":"From Jupyter Notebooks to Production: MLOps Workshop at Tech Bor√•s","uri":"/mlops-workshop-tech-boras/"},{"categories":null,"content":"MLOps \u0026 AI Consulting in Bor√•s This was the third workshop in the AI Lab series at University of Bor√•s, focused on practical MLOps for developers and engineers. I provide AI and data engineering consulting for businesses in Bor√•s and throughout Sweden. If you need help implementing MLOps infrastructure, building ML pipelines, or moving models from experimentation to production, reach out. ","date":"2025-09-23","objectID":"/mlops-workshop-tech-boras/:5:0","tags":null,"title":"From Jupyter Notebooks to Production: MLOps Workshop at Tech Bor√•s","uri":"/mlops-workshop-tech-boras/"},{"categories":null,"content":"Learn how to build text classifiers with just a handful of training examples using SetFit and Transformer models. A perfect first AI project for businesses. Practical tutorial from Tech Bor√•s AI Lab Workshop 2.","date":"2025-09-10","objectID":"/setfit-nlp-workshop-tech-boras/","tags":null,"title":"Powerful NLP with SetFit and Few-Shot Learning","uri":"/setfit-nlp-workshop-tech-boras/"},{"categories":null,"content":"On September 9, I ran the second workshop in the AI Lab series at University of Bor√•s. This time we tackled a common business problem that you run into all the time when starting an AI project: You have the data, but it is unlabeled. This post shows how to handle that challenge with few-shot learning. Workshop om Transformers och SetFit p√• H√∂gskolan i Bor√•s, 9 september Modern NLP (Natural Language Processing) tools like SetFit make few-shot learning practical with code you can run locally on your own hardware. Small language models like BERT variants are lightweight enough to run on consumer GPUs, making advanced NLP accessible without cloud infrastructure dependency or recurring costs. This is an excellent first AI/ML project for companies wanting to get started with data-driven work! ","date":"2025-09-10","objectID":"/setfit-nlp-workshop-tech-boras/:0:0","tags":null,"title":"Powerful NLP with SetFit and Few-Shot Learning","uri":"/setfit-nlp-workshop-tech-boras/"},{"categories":null,"content":"The challenge of limited training data Text classification solves real business problems. To mention a few, you can: sort support tickets by priority, filter out spam, route customer inquiries to the right department, analyze sentiment (what people think) in product reviews. A traditional machine learning approach requires thousands of labeled examples in a so-called dataset. That means you need someone to manually label 5,000+ emails as ‚Äúspam‚Äù or ‚Äúnot spam‚Äù before training a model can begin. That can be expensive and slow (and boring), which means most organizations don‚Äôt have thousands of pre-labeled examples sitting around. This is where the SetFit method comes in: it uses powerful pre-trained transformer models that we fine-tune on as few as two examples per class. Much easier to manage than 5,000 examples! ","date":"2025-09-10","objectID":"/setfit-nlp-workshop-tech-boras/:1:0","tags":null,"title":"Powerful NLP with SetFit and Few-Shot Learning","uri":"/setfit-nlp-workshop-tech-boras/"},{"categories":null,"content":"How Transformers changed NLP Transformer models like BERT revolutionized natural language processing by understanding word context. Unlike older methods that treat words as isolated tokens, BERT captures meaning based on surrounding words. Consider these sentences: ‚ÄúHe biked to work.‚Äù ‚ÄúHe drove his car to work.‚Äù ‚ÄúPeter decided to take his bike to the beach.‚Äù BERT understands that ‚Äúbiked‚Äù and ‚Äúbike‚Äù relate to the same concept, while ‚Äúdrove his car‚Äù represents a different mode of transport. This contextual understanding is what makes modern NLP powerful. And what‚Äôs extra good is that there are open-source platforms like HuggingFace filled with these small, pre-trained BERT models that already know a lot about our world. We just need to provide a few examples of our task to retrain the models to become good at what we want. ","date":"2025-09-10","objectID":"/setfit-nlp-workshop-tech-boras/:2:0","tags":null,"title":"Powerful NLP with SetFit and Few-Shot Learning","uri":"/setfit-nlp-workshop-tech-boras/"},{"categories":null,"content":"Understanding semantic similarity in text The context in which you read a text matters for the concept of ‚Äúsimilarity‚Äù. Whether two sentences are ‚Äúsimilar‚Äù depends entirely on what you‚Äôre measuring. If we look from the perspective of public transportation, we might be interested in knowing which mode of transport is mentioned in the text. Then we can imagine that examples might be paired like this: Negative pair (different modes of transport): ‚ÄúHe biked to work.‚Äù ‚ÄúHe drove his car to work.‚Äù Positive pair (same mode of transport): ‚ÄúHe biked to work.‚Äù ‚ÄúPeter decided to take his bike to the beach.‚Äù Negative pair (different modes of transport): ‚ÄúPeter decided to take his bike to the beach.‚Äù ‚ÄúHe drove his car to work.‚Äù But if we‚Äôre interested in knowing where someone is going, we would need to pair the examples in a completely different way. This is important because transformer models learn these contextual relationships from massive datasets when they were initially trained. That means the models have seen data that might not match exactly what you want to measure! And this is where SetFit comes in. ","date":"2025-09-10","objectID":"/setfit-nlp-workshop-tech-boras/:3:0","tags":null,"title":"Powerful NLP with SetFit and Few-Shot Learning","uri":"/setfit-nlp-workshop-tech-boras/"},{"categories":null,"content":"SetFit: Few-Shot Learning for Text Classification SetFit combines pre-trained Transformer models with efficient fine-tuning on your problem from the perspective you want to adopt. That is, is it interesting to know the mode of transport or the destination? And thanks to SetFit, we can achieve very high accuracy with just 2-16 labeled examples. SetFit works in two stages: Contrastive learning: Train on sentence pairs to learn which examples are similar and which are different Classification head: Train a simple classifier on top of the learned embeddings Doing it this way leverages the vast knowledge already baked into transformer models. You‚Äôre not teaching the model language and concepts from scratch. Instead, you‚Äôre teaching it your specific classification task using the language understanding the model already has. This gives us fast, lightweight, production-ready text classifiers trained on a fraction of the data that traditional methods require. ","date":"2025-09-10","objectID":"/setfit-nlp-workshop-tech-boras/:4:0","tags":null,"title":"Powerful NLP with SetFit and Few-Shot Learning","uri":"/setfit-nlp-workshop-tech-boras/"},{"categories":null,"content":"Building a text classifier with SetFit This example is based on the workshop repository: github.com/krjoha/ai-lab-setfit If you want to see the full example, you can look at one of the notebooks in the repository. Here‚Äôs a code example from there: ","date":"2025-09-10","objectID":"/setfit-nlp-workshop-tech-boras/:5:0","tags":null,"title":"Powerful NLP with SetFit and Few-Shot Learning","uri":"/setfit-nlp-workshop-tech-boras/"},{"categories":null,"content":"Installation Use uv to create a virtual python environment. # Create a virtual environment in a .venv folder and install all project dependencies uv sync ","date":"2025-09-10","objectID":"/setfit-nlp-workshop-tech-boras/:5:1","tags":null,"title":"Powerful NLP with SetFit and Few-Shot Learning","uri":"/setfit-nlp-workshop-tech-boras/"},{"categories":null,"content":"Complete Training Pipeline from datasets import load_dataset from setfit import SetFitModel, Trainer, TrainingArguments, sample_dataset # Load the Amazon Massive Intent dataset (Swedish) train_dataset = load_dataset(\"SetFit/amazon_massive_intent_sv-SE\", split=\"train\") test_dataset = load_dataset(\"SetFit/amazon_massive_intent_sv-SE\", split=\"test\") # Sample just 1 example per class (60 examples from 60 intent classes) train_sample = sample_dataset( train_dataset, label_column=\"label\", num_samples=1 ) # Load a pre-trained embedding model model = SetFitModel.from_pretrained(\"nomic-ai/modernbert-embed-base\") # Configure training args = TrainingArguments( batch_size=32, num_epochs=1, ) # Initialize trainer trainer = Trainer( model=model, args=args, train_dataset=train_sample, eval_dataset=test_dataset, metric='accuracy', ) # Train the model trainer.train() # Evaluate on test set results = trainer.evaluate(test_dataset) print(f\"Accuracy: {results['accuracy']:.2%}\") # Make predictions on new Swedish text predictions = model.predict([ \"Sl√§ck lampan\", # Turn off the light \"spela vikingarna\", # Play Vikingarna (music) \"starta dammsugaren\", # Start the vacuum cleaner ]) print(predictions) ","date":"2025-09-10","objectID":"/setfit-nlp-workshop-tech-boras/:5:2","tags":null,"title":"Powerful NLP with SetFit and Few-Shot Learning","uri":"/setfit-nlp-workshop-tech-boras/"},{"categories":null,"content":"What this code does Dataset loading: Load Amazon Massive Intent dataset with 60 different intent classes in Swedish Few-shot sampling: Sample just 1 example per class (60 total examples from 11,514 available) Model initialization: Load a pre-trained multilingual embedding model Training: The trainer generates sentence pairs and fine-tunes the model Evaluation: Test accuracy on 2,974 unseen examples Prediction: Classify new Swedish voice assistant commands With just 60 examples total (1 per class), this model achieves sufficiently high accuracy to become useful for so-called ‚Äúintent classification‚Äù. As mentioned, traditional approaches would need thousands of examples per class to achieve similar results. ","date":"2025-09-10","objectID":"/setfit-nlp-workshop-tech-boras/:5:3","tags":null,"title":"Powerful NLP with SetFit and Few-Shot Learning","uri":"/setfit-nlp-workshop-tech-boras/"},{"categories":null,"content":"Running locally with GPU Small language models like BERT are lightweight enough to run on consumer GPUs. Unlike large language models, models like modernbert-embed-base require only a few gigabytes of GPU memory. Training Transformer models needs GPU acceleration. Even with SetFit‚Äôs efficiency, CPU training can sometimes be slow and impractical. So it‚Äôs good to use your computer‚Äôs GPU if there is one. You can check that by running: # Verify NVIDIA GPU is detected nvidia-smi # For Macbook with Apple Silicon (M1/M2/M3/M4/M5) # PyTorch will automatically detect and use MPS (Metal Performance Shaders) If you have an NVIDIA GPU with CUDA support or a Macbook with Apple Silicon, PyTorch will use hardware acceleration automatically. The training code above with 60 examples takes a few seconds instead of several hours with only CPU. ","date":"2025-09-10","objectID":"/setfit-nlp-workshop-tech-boras/:6:0","tags":null,"title":"Powerful NLP with SetFit and Few-Shot Learning","uri":"/setfit-nlp-workshop-tech-boras/"},{"categories":null,"content":"Local vs Cloud Development Running locally gives you control. No session timeouts. No random disconnects. Work directly with local datasets. Your environment persists between sessions. But if you don‚Äôt have local GPU access, Kaggle provides free GPU notebooks. ","date":"2025-09-10","objectID":"/setfit-nlp-workshop-tech-boras/:6:1","tags":null,"title":"Powerful NLP with SetFit and Few-Shot Learning","uri":"/setfit-nlp-workshop-tech-boras/"},{"categories":null,"content":"Alternative: Kaggle Notebooks Kaggle offers free GPU in their notebook environment. But it requires a registered account + phone verification to prevent abuse. In exchange, you get access to an Nvidia T4 GPU. Phone verification: Log into your account at kaggle.com/settings Follow the instructions to add your phone number After verification, your notebooks get internet access and GPU support Enable GPU: Open the Kaggle Notebook Click Settings ‚Üí Accelerator ‚Üí GPU T4 x2 (avoid P100, it‚Äôs older) Your session now has GPU acceleration Install SetFit: Run the first cell to start your session Click Add-ons ‚Üí Install Dependencies Paste: pip install setfit Click Run, then Save There‚Äôs a version of the workshop notebook on Kaggle with these packages pre-configured. ","date":"2025-09-10","objectID":"/setfit-nlp-workshop-tech-boras/:6:2","tags":null,"title":"Powerful NLP with SetFit and Few-Shot Learning","uri":"/setfit-nlp-workshop-tech-boras/"},{"categories":null,"content":"Get started with few-shot NLP SetFit makes it possible to solve real business problems with NLP without needing thousands of labeled examples. Because pre-trained transformer models already understand language, you just need to teach them your specific task. This requires far less data than training from scratch. An excellent first project! Want to try it yourself? Clone the workshop repository and train your first few-shot classifier: Repository: github.com/krjoha/ai-lab-setfit You can have a working text classifier running in under 10 minutes. And it‚Äôs free to run locally if you have a GPU in your computer! Kristoffer Johansson, lecturer and create of the AI Lab concept at Tech Bor√•s ","date":"2025-09-10","objectID":"/setfit-nlp-workshop-tech-boras/:7:0","tags":null,"title":"Powerful NLP with SetFit and Few-Shot Learning","uri":"/setfit-nlp-workshop-tech-boras/"},{"categories":null,"content":"NLP \u0026 AI Consulting in Bor√•s This workshop was part of the AI Lab series at University of Bor√•s, focused on practical AI and NLP for developers. I provide AI and data engineering consulting for businesses in Bor√•s and throughout Sweden. If you need help implementing NLP solutions or want to explore few-shot learning for your use case, reach out. ","date":"2025-09-10","objectID":"/setfit-nlp-workshop-tech-boras/:8:0","tags":null,"title":"Powerful NLP with SetFit and Few-Shot Learning","uri":"/setfit-nlp-workshop-tech-boras/"},{"categories":null,"content":"Practical machine learning insights from our developer workshop at University of Bor√•s. Learn ML fundamentals, understand AI hype vs. reality, and start building with Python. Expert ML consulting in Bor√•s.","date":"2025-08-29","objectID":"/intro-to-ml-workshop-tech-boras/","tags":null,"title":"Machine Learning Workshop in Bor√•s","uri":"/intro-to-ml-workshop-tech-boras/"},{"categories":null,"content":"On August 26, I ran the first of three workshops at the University of Bor√•s. The objective was to introduce 25 developers to machine learning and have them build a bunch of models while avoiding common pitfalls. Machine learning workshop at University of Bor√•s, August 26 If you missed it, this post covers the material used, a recommended learning path, and some words about the current AI hype bubble. ","date":"2025-08-29","objectID":"/intro-to-ml-workshop-tech-boras/:0:0","tags":null,"title":"Machine Learning Workshop in Bor√•s","uri":"/intro-to-ml-workshop-tech-boras/"},{"categories":null,"content":"Getting Started with Machine Learning using Kaggle To get started in an online Python environment without local setup, Kaggle is a solid choice. It provides interactive courses where you write code directly in the browser. No installation, no configuration. Here‚Äôs how to begin: Create a free account at kaggle.com Go to the ‚ÄúLearn‚Äù section Start the ‚ÄúIntro to Machine Learning‚Äù course Write code, run it, see results Direct link: https://www.kaggle.com/learn/intro-to-machine-learning The course uses Python and scikit-learn to build predictive models. You learn by doing, which beats reading theory. ","date":"2025-08-29","objectID":"/intro-to-ml-workshop-tech-boras/:1:0","tags":null,"title":"Machine Learning Workshop in Bor√•s","uri":"/intro-to-ml-workshop-tech-boras/"},{"categories":null,"content":"Code Example: Your First Machine Learning Model The Kaggle course walks through building a simple predictive model. Here‚Äôs one example: loading housing data and training a decision tree to predict home prices. import pandas as pd from sklearn.tree import DecisionTreeRegressor # Path of the file to read iowa_file_path = '../input/home-data-for-ml-course/train.csv' home_data = pd.read_csv(iowa_file_path) y = home_data.SalePrice feature_names = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd'] X = home_data[feature_names] # Define model iowa_model = DecisionTreeRegressor(random_state=1) # Fit model iowa_model.fit(X, y) print(\"Making predictions for the following 5 houses:\") print(X.head()) print(\"The predictions are\") print(iowa_model.predict(X.head())) This demonstrates the basic ML workflow: load data, select features, train a model, make predictions. The Kaggle course breaks down each step. ","date":"2025-08-29","objectID":"/intro-to-ml-workshop-tech-boras/:2:0","tags":null,"title":"Machine Learning Workshop in Bor√•s","uri":"/intro-to-ml-workshop-tech-boras/"},{"categories":null,"content":"Key Concepts from the Workshop These are the fundamental insights that we disussed during the workshop. If you understand these, you‚Äôre ahead of most people talking about AI. ","date":"2025-08-29","objectID":"/intro-to-ml-workshop-tech-boras/:3:0","tags":null,"title":"Machine Learning Workshop in Bor√•s","uri":"/intro-to-ml-workshop-tech-boras/"},{"categories":null,"content":"Machine Learning is Pattern Recognition ML algorithms find patterns in historical data. You feed them examples, and they learn to recognize patterns that apply to new, unseen data. This differs from traditional programming, where you write explicit rules. In ML, the algorithm discovers the rules from data. ","date":"2025-08-29","objectID":"/intro-to-ml-workshop-tech-boras/:3:1","tags":null,"title":"Machine Learning Workshop in Bor√•s","uri":"/intro-to-ml-workshop-tech-boras/"},{"categories":null,"content":"History Repeats itself ML models rely on one important assumption: Assumption The patterns in your historical data will apply to future data. When the underlying patterns change, your model fails. ML works well for stable domains like predicting house prices or detecting spam. It struggles in rapidly changing environments. It is not magic. Critical Rule Always evaluate your model on unseen data. No exceptions. Train on data and test on the same data? You‚Äôre measuring memorization, not prediction. Use a test set to measure real performance. A model that performs well on training data but fails on new data is worthless. ","date":"2025-08-29","objectID":"/intro-to-ml-workshop-tech-boras/:3:2","tags":null,"title":"Machine Learning Workshop in Bor√•s","uri":"/intro-to-ml-workshop-tech-boras/"},{"categories":null,"content":"AI is Overrated AI is powerful, but the current buzz outpaces reality. For most businesses, practical supervised machine learning solves more problems than chasing the latest AI trends. The hype bubble AI is unprofitable for most companies and heavily subsidized by venture capital. Focus on solving real problems with proven techniques first. ","date":"2025-08-29","objectID":"/intro-to-ml-workshop-tech-boras/:3:3","tags":null,"title":"Machine Learning Workshop in Bor√•s","uri":"/intro-to-ml-workshop-tech-boras/"},{"categories":null,"content":"Data is Your Moat The real value in machine learning is data. Acquiring and cleaning good data is the hardest part. Competitive Advantage A unique, high-quality dataset builds a competitive moat. Anyone can train a model. Few companies have unique, valuable data. Invest in data infrastructure and data quality. That‚Äôs where sustainable competitive advantage lives. Participants working through hands-on ML exercises ","date":"2025-08-29","objectID":"/intro-to-ml-workshop-tech-boras/:3:4","tags":null,"title":"Machine Learning Workshop in Bor√•s","uri":"/intro-to-ml-workshop-tech-boras/"},{"categories":null,"content":"Machine Learning Consulting in Bor√•s This workshop was the first in a series at University of Bor√•s focused on practical AI and machine learning for developers. I provide AI and data engineering consulting for businesses in Bor√•s and throughout Sweden. If you need help implementing machine learning solutions or want to cut through the AI hype to find what actually works for your business, reach out. ","date":"2025-08-29","objectID":"/intro-to-ml-workshop-tech-boras/:4:0","tags":null,"title":"Machine Learning Workshop in Bor√•s","uri":"/intro-to-ml-workshop-tech-boras/"},{"categories":null,"content":"Use supervised learning to optimize your organization. Generative AI, large language models (LLM), RAG \u0026 agents are buzzwords roght now, but the truly great values can be found within supervised learning!","date":"2025-02-02","objectID":"/supervised-learning-is-valuable/","tags":null,"title":"Supervised learning creates more value than generative AI","uri":"/supervised-learning-is-valuable/"},{"categories":null,"content":"What gives you a greater competitive advantage than generative AI, language models, RAG \u0026 agents? Supervised learning ","date":"2025-02-02","objectID":"/supervised-learning-is-valuable/:0:0","tags":null,"title":"Supervised learning creates more value than generative AI","uri":"/supervised-learning-is-valuable/"},{"categories":null,"content":"The value of supervised learning A lot of attention and resources are being directed toward the previously mentioned buzzwords, but remember that the real, significant value lies in supervised learning. In the graphic below, Andrew Ng illustrates different areas of AI. We see generative AI, which has been the hot topic for the past two years, but also supervised learning, unsupervised learning, and reinforcement learning‚Äîthree fundamental pillars of machine learning. The size of the circles indicates the current value of these areas and how much Andrew predicts they will grow over the next three years. Supervised learning looks pretty promising, doesn‚Äôt it? üëÄ Sure, generative AI might be growing at a faster pace, but supervised learning still seems to hold a clear first place. ","date":"2025-02-02","objectID":"/supervised-learning-is-valuable/:1:0","tags":null,"title":"Supervised learning creates more value than generative AI","uri":"/supervised-learning-is-valuable/"},{"categories":null,"content":"Use cases Let‚Äôs say we accept this reasoning and set generative AI aside for a moment, what can we actually do with supervised learning? How can you use it to improve your business? üí∞üíµ Things you can do with supervised learning: Label things. (Classification) ‚ÄúIs this a picture of a chihuahua or a muffin? Will the user click on the ad or not?‚Äù Make predictions. (Regression) ‚ÄúHow delayed will my train be? How many people will visit my restaurant next week?‚Äù Recommend a new TV show based on last week‚Äôs binge-watch of The Bear üêªüë®‚Äçüç≥. There are countless problems and challenges that AI can help solve, and you‚Äîthe expert in your business and domain‚Äîknow best what‚Äôs valuable to tackle! That said, building AI solutions is more complex than just programming logic into your application, so you might not even need supervised learning. Sometimes, a few well-placed lines of code are all it takes. Either way, if any of this sounds interesting, feel free to reach out! ","date":"2025-02-02","objectID":"/supervised-learning-is-valuable/:1:1","tags":null,"title":"Supervised learning creates more value than generative AI","uri":"/supervised-learning-is-valuable/"},{"categories":null,"content":"Credits Andrew Ng‚Äôs presentation on AI and machine learning: Andrew Ng: Opportunities in AI - 2023 PS. If you‚Äôre looking for your next TV show to watch, I highly recommend Severance . Work-life balance at its finest! üî•üî• ","date":"2025-02-02","objectID":"/supervised-learning-is-valuable/:1:2","tags":null,"title":"Supervised learning creates more value than generative AI","uri":"/supervised-learning-is-valuable/"},{"categories":null,"content":"Chihuahua or muffin? What is it, a Chihuahua or a muffin? ","date":"2025-02-02","objectID":"/supervised-learning-is-valuable/:1:3","tags":null,"title":"Supervised learning creates more value than generative AI","uri":"/supervised-learning-is-valuable/"},{"categories":null,"content":"The developer experience (DevEx) plays a key role in any organization building software - whether it‚Äôs good or bad. Let us help you make your developers happier and more productive.","date":"2025-01-26","objectID":"/developer-experience-matters-a-lot/","tags":null,"title":"Developer experience matters a lot","uri":"/developer-experience-matters-a-lot/"},{"categories":null,"content":"In order for develovers to be succ.. üößüö® Developers needs a.. üößüö® Ugh! It‚Äôs no fun to be interrupted when you are just getting started. ","date":"2025-01-26","objectID":"/developer-experience-matters-a-lot/:0:0","tags":null,"title":"Developer experience matters a lot","uri":"/developer-experience-matters-a-lot/"},{"categories":null,"content":"Why does it feel like an obstacle course? This is what the developer experience (DevEx) feels like in many larger, long-established organizations with significant technical debt. Add to that the constant pinging of chat windows and overflowing inboxes, and you‚Äôve got a recipe for sluggish deliveries and frustrated developers! ","date":"2025-01-26","objectID":"/developer-experience-matters-a-lot/:1:0","tags":null,"title":"Developer experience matters a lot","uri":"/developer-experience-matters-a-lot/"},{"categories":null,"content":"Scenario - code silos Imagine this: you‚Äôve just been hired as a developer at Acme Big Tech Inc. Your task is to create a new application to manage the company‚Äôs quotes. ‚ÄúNo problem, I‚Äôll have a first version ready by next week!‚Äù you say as you reach for the keyboard‚Ä¶ After some intense typing, you get to the part where you need to save information to a database. ‚ÄúSurely one of my 500 developer colleagues has solved this 100 times before. I‚Äôll check Git and see how they did it‚Äù you think as you open a new tab with GitLab in your browser. Empty. What? Where‚Äôre all the repositories? Turns out all code repositories are set to ‚Äúprivate‚Äù by default. And apparently, there isn‚Äôt just one instance of GitLab‚Äîthere are at least three, though you don‚Äôt know about the others yet. On top of that, you have no idea which team to ask for access because, as it turns out, GitLab groups are also set to ‚Äúprivate‚Äù by default. ","date":"2025-01-26","objectID":"/developer-experience-matters-a-lot/:1:1","tags":null,"title":"Developer experience matters a lot","uri":"/developer-experience-matters-a-lot/"},{"categories":null,"content":"The solution? This is an example of an unnecessary hurdle that shouldn‚Äôt exist. The solution? Start by changing the default setting to ‚Äúinternal‚Äù, making all code visible to all developers. And maybe consider consolidating those other GitLab instances while you‚Äôre at it? Even better: What if Acme Big Tech Inc. had an Internal Developer Platform (IDP) like Backstage from Spotify ? It would make things so much easier by showing which services are running and which team is responsible for them. What if the processes were designed for speed and trust, without forcing pull request reviews on everything? Instead of waiting for a review, sit down and work together! Everyone learns more, and maybe it even becomes fun to tackle technical debt. What would happen to developers motivation and productivity then? A hurdle and a rusty ladder, generated by Midjourney. Prompt: An obstacle wall part of an obstacle course, ladder, dystopian, candid, rust, green grass ","date":"2025-01-26","objectID":"/developer-experience-matters-a-lot/:1:2","tags":null,"title":"Developer experience matters a lot","uri":"/developer-experience-matters-a-lot/"},{"categories":null,"content":"We are AI \u0026 ML consultants that develop innovative solutions for a sustainable future.","date":"2025-01-05","objectID":"/about/","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"Our mission We develop machine learning solutions that drive efficiency, fairness, and sustainability. By tackling real-world challenges with innovative technology, we aim to create meaningful impact and long-term value for businesses and society. ","date":"2025-01-05","objectID":"/about/:1:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"Located in Sweden Based in southwest Sweden, we serve clients in the greater Gothenburg area, surrounding regions, and remotely across Europe. Pinus sylvestris, generated by Midjourney. Prompt: A single pine tree, vector art, minimalist --sref https://cdn.pixabay.com/photo/2017/01/31/15/37/evergreen-2025158_1280.png ","date":"2025-01-05","objectID":"/about/:1:1","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"Pine Grove Interactive pgi.dev is owned and run by PGI AB (Swedish company registration number: 559515-1522) ","date":"2025-01-05","objectID":"/about/:1:2","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"Our consultants work with you to build innovative solutions for a sustainable and fair society. Get in touch today to make your operations more efficient using AI and ML!","date":"2025-01-05","objectID":"/offer/","tags":null,"title":"Services in AI \u0026 Data Engineering","uri":"/offer/"},{"categories":null,"content":"We leverage our expertise in AI and data engineering to make your business more efficient. Whether you already have a data team or are just starting out, we provide the resources you need to succeed with your data projects. ","date":"2025-01-05","objectID":"/offer/:0:0","tags":null,"title":"Services in AI \u0026 Data Engineering","uri":"/offer/"},{"categories":null,"content":"Upskilling in AI \u0026 Machine Learning Our experts provide tailored training programs to equip you and your developers with the skills needed to work effectively with AI and machine learning. The education package offers hands-on workshops, practical guidance, and actionable insights designed to address your business needs. ","date":"2025-01-05","objectID":"/offer/:1:0","tags":null,"title":"Services in AI \u0026 Data Engineering","uri":"/offer/"},{"categories":null,"content":"Data pipelines Efficient data pipelines are the backbone of any successful data strategy. We design and implement robust, scalable pipelines that streamline data flow, ensuring that your data is clean, accessible, and ready for analysis. Our data engineers can help you reduce the costs of your data platform. ","date":"2025-01-05","objectID":"/offer/:1:1","tags":null,"title":"Services in AI \u0026 Data Engineering","uri":"/offer/"},{"categories":null,"content":"AI to power your applications Integrating AI into your existing applications can enhance functionality, improve efficiency, and unlock new capabilities. We can help you create new applications that drive efficiency and unlock possibilities that wouldn‚Äôt be possible to achieve without leveraging your data. ","date":"2025-01-05","objectID":"/offer/:1:2","tags":null,"title":"Services in AI \u0026 Data Engineering","uri":"/offer/"},{"categories":null,"content":"Reach out Contact us to empower your team with the tools and knowledge to succeed with AI-initiatives! A developer working in the wild, generated by Midjourney. Prompt: A young man working on his laptop under a pine tree, back towards camera, squirrel sitting next to him, vector art, minimalist --sref https://pgi.dev/about/pine-tree.webp ","date":"2025-01-05","objectID":"/offer/:1:3","tags":null,"title":"Services in AI \u0026 Data Engineering","uri":"/offer/"}]